geom_node_point(color = "darkslategray4", size = 3) +
geom_node_text(aes(label = name), vjust = 1.8, size = 2.5) +
labs(title = "Figure 5: Word Network: Tweets using my hashtag",
subtitle = "Text mining twitter data",
x = "", y = "")
plotly::ggplotly(a)
# plot word network
my_words_counts %>%
filter(n >= 3) %>%
graph_from_data_frame() %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = .6, edge_width = n)) +
geom_node_point(color = "darkslategray4", size = 3) +
geom_node_text(aes(label = name), vjust = 1.8, size = 2.5) +
labs(title = "Figure 5: Word Network: Tweets using my hashtag",
subtitle = "Text mining twitter data",
x = "", y = "")
my_twts[1,] %>%
mutate(text = str_replace_all(text, replace_reg, "")) %>%
dplyr::select(text) %>%
unnest_tokens(output = paired_words,
input = text,
token = "ngrams",
n = 2)
my_twts[1,'text']
data.frame(text = c("The result of separating bigrams is helpful for exploratory analyses of the text."))
data.frame(text = c("The result of separating bigrams is helpful for exploratory analyses of the text."))%>%
mutate(text = str_replace_all(text, replace_reg, "")) %>%
dplyr::select(text) %>%
unnest_tokens(output = paired_words,
input = text,
token = "ngrams",
n = 2)
60*60*24
60*60*24/8
1800*6
0.017/0.098
0.098*0.17
0.098*0.1734
# Package names
packages <- c("rtweet", "tidytext", "tidyverse", "wordcloud2", "textdata", "sentiment.ai", "SentimentAnalysis", "sentimentr")
# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
install.packages(packages[!installed_packages])
}
# Load packages
invisible(lapply(packages, library, character.only = TRUE))
# Load the package
require(sentiment.ai)
require(SentimentAnalysis)
require(sentimentr)
install_sentiment.ai(envname = "r-sentiment-ai",
method = "conda",
python_version = "3.8.10")
check_sentiment.ai()
text <- c(
"What a great car. It stopped working after a week.",
"Steve Irwin working to save endangered species",
"Bob Ross teaching people how to paint",
"I saw Adolf Hitler on my vacation in Argentina...",
"the resturant served human flesh",
"the resturant is my favorite!",
"the resturant is my favourite!",
"this restront is my FAVRIT innit!",
"the resturant was my absolute favorite until they gave me food poisoning",
"This fantastic app freezes all the time!",
"I learned so much on my trip to Hiroshima museum last year!",
"What happened to the people of Hiroshima in 1945",
"I had a blast on my trip to Nagasaki",
"The blast in Nagasaki",
"I love watching scary horror movies",
"This package offers so much more nuance to sentiment analysis!",
"you remind me of the babe. What babe? The babe with the power! What power? The power of voodoo. Who do? You do. Do what? Remind me of the babe!"
)
# sentiment.ai
sentiment.ai.score <- sentiment_score(text)
# From Sentiment Analysis
sentimentAnalysis.score <- analyzeSentiment(text)$SentimentQDAP
# From sentimentr
sentimentr.score <- sentiment_by(get_sentences(text), 1:length(text))$ave_sentiment
example <- data.frame(target = text,
sentiment.ai = sentiment.ai.score,
sentimentAnalysis = sentimentAnalysis.score,
sentimentr = sentimentr.score)
example
example %>%
kableExtra::kable()
rownames(example) <- NULL
example %>%
kableExtra::kable()
# whatever name you assigned to your created app
appname <- "UrbanAnalytics_tutorial"
# create token named "twitter_token"
# the keys used should be replaced by your own keys obtained by creating the app
twitter_token <- create_token(
app = appname,
consumer_key = Sys.getenv("twitter_key"),
consumer_secret = Sys.getenv("twitter_key_secret"),
access_token = Sys.getenv("twitter_access_token"),
access_secret = Sys.getenv("twitter_access_token_secret"))
# Get time lines
obama <- rtweet::get_timeline("BarackObama", n = 3200)
biden <- rtweet::get_timeline("JoeBiden", n=3200)
# Add screen nam
obama <- bind_cols(obama,
users_data(obama) %>% select(screen_name, location))
biden <- bind_cols(biden,
users_data(biden) %>% select(screen_name, location))
# Row-bind the two
tweets <- bind_rows(
obama %>% select(text, screen_name, created_at, retweet_count, favorite_count),
biden %>% select(text, screen_name, created_at, retweet_count, favorite_count)
)
# Regex that matches URL-type string
replace_reg <- "http[s]?://[A-Za-z\\d/\\.]+|&amp;|&lt;|&gt;"
# Tidy the string
tidy_tweets_words <- tweets %>%
# Drop retweets
filter(!str_detect(text, "^RT")) %>%
# Drop URLs
mutate(text = str_replace_all(text, replace_reg, ""),
text = gsub("@", "", text)) %>%
# Add id column
mutate(id = row_number())
tidy_tweets_words
test_txt <- c("\n\n", "is there any different?", "is there \n\nany difference?")
sentiment_score(text_txt)
test_txt <- c("\n\n", "is there any different?", "is there \n\nany difference?")
test_txt
sentiment_score(text_txt)
sentiment_score(test_txt)
# Regex that matches URL-type string
replace_reg <- "http[s]?://[A-Za-z\\d/\\.]+|&amp;|&lt;|&gt;"
# Tidy the string
tidy_tweets_words <- tweets %>%
# Drop retweets
filter(!str_detect(text, "^RT")) %>%
# Drop URLs
mutate(text = str_replace_all(text, replace_reg, ""),
text = gsub("@", "", text),
text = gsub("\n\n", "", text)) %>%
# Add id column
mutate(id = row_number())
tidy_tweets_words
sentiment.twt <- sentiment_score(tidy_tweets_words$text)
tidy_tweets_words <- tidy_tweets_words %>%
mutate(sentiment = sentiment_score(text))
tidy_tweets_words %>%
mutate(ym = format(created_at, "%Y-%m")) %>%
group_by(screen_name, ym) %>%
summarise(sentiment = mean(sentiment),
favorite_count = log(mean(favorite_count))) %>%
mutate(ym = ym(ym)) %>%
ggplot(data = .) +
geom_line(mapping = aes(x = ym, y = sentiment, color = favorite_count), lwd = 1) +
facet_wrap(~screen_name)
# Package names
packages <- c("rtweet", "tidytext", "tidyverse", "wordcloud2", "textdata", "sentiment.ai", "SentimentAnalysis", "sentimentr", "lubridate")
# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
# Load packages
invisible(lapply(packages, library, character.only = TRUE))
tidy_tweets_words %>%
mutate(ym = format(created_at, "%Y-%m")) %>%
group_by(screen_name, ym) %>%
summarise(sentiment = mean(sentiment),
favorite_count = log(mean(favorite_count))) %>%
mutate(ym = ym(ym)) %>%
ggplot(data = .) +
geom_line(mapping = aes(x = ym, y = sentiment, color = favorite_count), lwd = 1) +
facet_wrap(~screen_name)
exp(14)
exp(8)
tidy_tweets_words
tidy_tweets_words$retweet_count
tidy_tweets_words %>%
mutate(ym = format(created_at, "%Y-%m")) %>%
group_by(screen_name, ym) %>%
summarise(sentiment = mean(sentiment),
retweet_count = log(mean(retweet_count))) %>%
mutate(ym = ym(ym)) %>%
ggplot(data = .) +
geom_line(mapping = aes(x = ym, y = sentiment, color = retweet_count), lwd = 1) +
facet_wrap(~screen_name)
?ggplot2::lab
?ggplot2::labs
tidy_tweets_words %>%
mutate(ym = format(created_at, "%Y-%m")) %>%
group_by(screen_name, ym) %>%
summarise(sentiment = mean(sentiment),
retweet_count = log(mean(retweet_count))) %>%
mutate(ym = ym(ym)) %>%
ggplot(data = .) +
geom_line(mapping = aes(x = ym, y = sentiment, color = retweet_count), lwd = 1) +
facet_wrap(~screen_name) +
labs(x = "Time Line",
y = "Sentiment Score",
title = "Sentiment Score of Tweets from US presidents",
subtitle = "Sentiment Score: -1 (negative) ~ +1 (positive)")
tidy_tweets_words %>%
mutate(ym = format(created_at, "%Y-%m")) %>%
group_by(screen_name, ym) %>%
summarise(sentiment = mean(sentiment),
retweet_count = log(mean(retweet_count))) %>%
mutate(ym = ym(ym)) %>%
ggplot(data = .) +
geom_line(mapping = aes(x = ym, y = sentiment, color = retweet_count), lwd = 1) +
facet_wrap(~screen_name) +
labs(x = "Time Line",
y = "Sentiment Score \n-1 (negative) ~ +1 (positive)",
title = "Sentiment Score of Tweets from US presidents")
tidy_tweets_words %>%
mutate(ym = format(created_at, "%Y-%m")) %>%
group_by(screen_name, ym) %>%
summarise(sentiment = mean(sentiment),
retweet_count = log(mean(retweet_count))) %>%
mutate(ym = ym(ym)) %>%
ggplot(data = .) +
geom_line(mapping = aes(x = ym, y = sentiment, color = retweet_count), lwd = 1) +
facet_wrap(~screen_name) +
labs(x = "Time Line",
y = "Sentiment Score \n",
title = "Sentiment Score of Tweets from US presidents",
subtitle = "Sentiment Score: -1 (negative) ~ +1 (positive)")
tidy_tweets_words %>%
mutate(ym = format(created_at, "%Y-%m")) %>%
group_by(screen_name, ym) %>%
summarise(sentiment = mean(sentiment),
retweet_count = log(mean(retweet_count))) %>%
mutate(ym = ym(ym)) %>%
ggplot(data = .) +
geom_line(mapping = aes(x = ym, y = sentiment, color = retweet_count), lwd = 1) +
facet_wrap(~screen_name) +
labs(x = "Time Line",
y = "Sentiment Score \n",
title = "Sentiment Score of Tweets from US presidents",
subtitle = "Sentiment Score: -1 (negative) ~ +1 (positive)",
color = "Retweet count (logged)")
tidy_tweets_words %>%
mutate(ym = format(created_at, "%Y-%m")) %>%
group_by(screen_name, ym) %>%
summarise(sentiment = mean(sentiment),
retweet_count = log(mean(retweet_count))) %>%
mutate(ym = ym(ym)) %>%
ggplot(data = .) +
geom_line(mapping = aes(x = ym, y = sentiment, color = retweet_count), lwd = 1) +
scale_color_gradient(low="blue", high="red") +
facet_wrap(~screen_name) +
labs(x = "Time Line",
y = "Sentiment Score \n",
title = "Sentiment Score of Tweets from US presidents",
subtitle = "Sentiment Score: -1 (negative) ~ +1 (positive)",
color = "Retweet count (logged)")
tidy_tweets_words %>%
mutate(ym = format(created_at, "%Y-%m")) %>%
group_by(screen_name, ym) %>%
summarise(sentiment = mean(sentiment),
retweet_count = log(mean(retweet_count))) %>%
mutate(ym = ym(ym)) %>%
ggplot(data = .) +
geom_line(mapping = aes(x = ym, y = sentiment, color = retweet_count), lwd = 1) +
facet_wrap(~screen_name) +
scale_color_gradient(low="blue", high="red") +
labs(x = "Time Line",
y = "Sentiment Score \n",
title = "Sentiment Score of Tweets from US presidents",
subtitle = "Sentiment Score: -1 (negative) ~ +1 (positive)",
color = "Retweet count (logged)")
tidy_tweets_words %>%
mutate(ym = format(created_at, "%Y-%m")) %>%
group_by(screen_name, ym) %>%
summarise(sentiment = mean(sentiment),
retweet_count = log(mean(retweet_count))) %>%
mutate(ym = ym(ym)) %>%
ggplot(data = .) +
geom_line(mapping = aes(x = ym, y = sentiment, color = retweet_count), lwd = 1) +
facet_wrap(~screen_name) +
scale_color_gradient(low="red", high="green") +
labs(x = "Time Line",
y = "Sentiment Score \n",
title = "Sentiment Score of Tweets from US presidents",
subtitle = "Sentiment Score: -1 (negative) ~ +1 (positive)",
color = "Retweet count (logged)")
check_sentiment.ai()
# Package names
packages <- c("rtweet", "tidytext", "tidyverse", "wordcloud2", "textdata", "sentiment.ai", "SentimentAnalysis", "sentimentr", "lubridate", "sentiment.ai", "SentimentAnalysis", "sentimentr")
# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
install.packages(packages[!installed_packages])
}
# Load packages
invisible(lapply(packages, library, character.only = TRUE))
check_sentiment.ai()
text <- c(
"What a great car. It stopped working after a week.",
"Steve Irwin working to save endangered species",
"Bob Ross teaching people how to paint",
"I saw Adolf Hitler on my vacation in Argentina...",
"the resturant served human flesh",
"the resturant is my favorite!",
"the resturant is my favourite!",
"this restront is my FAVRIT innit!",
"the resturant was my absolute favorite until they gave me food poisoning",
"This fantastic app freezes all the time!",
"I learned so much on my trip to Hiroshima museum last year!",
"What happened to the people of Hiroshima in 1945",
"I had a blast on my trip to Nagasaki",
"The blast in Nagasaki",
"I love watching scary horror movies",
"This package offers so much more nuance to sentiment analysis!",
"you remind me of the babe. What babe? The babe with the power! What power? The power of voodoo. Who do? You do. Do what? Remind me of the babe!"
)
# sentiment.ai
sentiment.ai.score <- sentiment_score(text)
# Package names
packages <- c("rtweet", "tidytext", "tidyverse", "wordcloud2", "textdata", "sentiment.ai", "SentimentAnalysis", "sentimentr", "lubridate", "sentiment.ai", "SentimentAnalysis", "sentimentr", 'here')
example
# From sentimentr
sentimentr.score <- sentiment(get_sentences(text), 1:length(text))$ave_sentiment
# From sentimentr
sentimentr.score <- sentimentr::sentiment(get_sentences(text), 1:length(text))$ave_sentiment
# From sentimentr
sentimentr.score <- sentimentr::sentiment_by(get_sentences(text), 1:length(text))$ave_sentiment
# Package names
packages <- c("rtweet", "tidytext", "tidyverse", "wordcloud2", "textdata", "sentiment.ai", "SentimentAnalysis", "sentimentr", "lubridate", "sentiment.ai", "SentimentAnalysis", "sentimentr", 'here')
# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
install.packages(packages[!installed_packages])
}
# Load packages
invisible(lapply(packages, library, character.only = TRUE))
# From sentimentr
sentimentr.score <- sentimentr::sentiment(get_sentences(text), 1:length(text))$ave_sentiment
get_sentences(text)
text <- c(
"What a great car. It stopped working after a week.",
"Steve Irwin working to save endangered species",
"Bob Ross teaching people how to paint",
"I saw Adolf Hitler on my vacation in Argentina...",
"the resturant served human flesh",
"the resturant is my favorite!",
"the resturant is my favourite!",
"this restront is my FAVRIT innit!",
"the resturant was my absolute favorite until they gave me food poisoning",
"This fantastic app freezes all the time!",
"I learned so much on my trip to Hiroshima museum last year!",
"What happened to the people of Hiroshima in 1945",
"I had a blast on my trip to Nagasaki",
"The blast in Nagasaki",
"I love watching scary horror movies",
"This package offers so much more nuance to sentiment analysis!",
"you remind me of the babe. What babe? The babe with the power! What power? The power of voodoo. Who do? You do. Do what? Remind me of the babe!"
)
get_sentences(text)
get_sentences(text)
SentimentAnalysis::analyzeSentiment(text)
?sentiment
# From sentimentr
sentimentr.score <- sentimentr::sentiment(
get_sentences(text), 1:length(text)
)$ave_sentiment
sentimentr.score
sentimentr::sentiment(
get_sentences(text), 1:length(text)
)
# From sentimentr
sentimentr.score <- sentimentr::sentiment_by(
get_sentences(text), 1:length(text)
)$ave_sentiment
sentimentr.score
sentimentr.score <- sentimentr::sentiment_by(
get_sentences(text), 1:length(text)
)
sentimentr.score
?sentiment_by
# Package names
packages <- c("rtweet", "tidytext", "tidyverse", "wordcloud2", "textdata", "sentiment.ai", "SentimentAnalysis", "sentimentr", "lubridate", "sentiment.ai", "SentimentAnalysis", 'here')
# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
install.packages(packages[!installed_packages])
}
# Load packages
invisible(lapply(packages, library, character.only = TRUE))
# install_sentiment.ai(envname = "r-sentiment-ai",
#                      method = "conda",
#                      python_version = "3.8.10")
init_sentiment.ai()
text <- c(
"What a great car. It stopped working after a week.",
"Steve Irwin working to save endangered species",
"Bob Ross teaching people how to paint",
"I saw Adolf Hitler on my vacation in Argentina...",
"the resturant served human flesh",
"the resturant is my favorite!",
"the resturant is my favourite!",
"this restront is my FAVRIT innit!",
"the resturant was my absolute favorite until they gave me food poisoning",
"This fantastic app freezes all the time!",
"I learned so much on my trip to Hiroshima museum last year!",
"What happened to the people of Hiroshima in 1945",
"I had a blast on my trip to Nagasaki",
"The blast in Nagasaki",
"I love watching scary horror movies",
"This package offers so much more nuance to sentiment analysis!",
"you remind me of the babe. What babe? The babe with the power! What power? The power of voodoo. Who do? You do. Do what? Remind me of the babe!"
)
# sentiment.ai
sentiment.ai.score <- sentiment_score(text)
# From Sentiment Analysis
sentimentAnalysis.score <- SentimentAnalysis::analyzeSentiment(text)$SentimentQDAP
# From sentimentr
sentimentr.score <- sentimentr::sentiment_by(
get_sentences(text), 1:length(text)
)$ave_sentiment
example <- data.frame(target = text,
sentiment.ai = sentiment.ai.score,
sentimentAnalysis = sentimentAnalysis.score)
rownames(example) <- NULL
example %>%
kableExtra::kable()
60*60*24
60*60*24*12
60*24*12
17280/60
288/60
60*60*24
60*60*24*12
60*60*24*12/(60*60)
sentiment_score(c("This installation process is so long!", "Only if it works in the end.", "But does it?"))
sentiment_score(c("This installation process is so long!", "Only if it works in the end.", "But does it?", "It does work."))
sentiment_score(c("This installation process is just so long!", "Only if it works in the end.", "But does it?", "It does work."))
sentiment_score(c("This installation process is too complicated!", "Only if it works in the end.", "But does it?", "It does work."))
sentiment_score(c("This installation process is too complicated!", "Only if it works in the end.", "But does it?", "It does work!"))
# Example texts
text <- c(
"What a great car. It stopped working after a week.",
"Steve Irwin working to save endangered species",
"Bob Ross teaching people how to paint",
"I saw Adolf Hitler on my vacation in Argentina...",
"the resturant served human flesh",
"the resturant is my favorite!",
"the resturant is my favourite!",
"this restront is my FAVRIT innit!",
"the resturant was my absolute favorite until they gave me food poisoning",
"This fantastic app freezes all the time!",
"I learned so much on my trip to Hiroshima museum last year!",
"What happened to the people of Hiroshima in 1945",
"I had a blast on my trip to Nagasaki",
"The blast in Nagasaki",
"I love watching scary horror movies",
"This package offers so much more nuance to sentiment analysis!",
"you remind me of the babe. What babe? The babe with the power! What power? The power of voodoo. Who do? You do. Do what? Remind me of the babe!"
)
# sentiment.ai
sentiment.ai.score <- sentiment_score(text)
# Sentiment Analysis
sentimentAnalysis.score <- SentimentAnalysis::analyzeSentiment(text)$SentimentQDAP
example <- data.frame(target = text,
sentiment.ai = sentiment.ai.score,
sentimentAnalysis = sentimentAnalysis.score)
rownames(example) <- NULL
example %>%
kableExtra::kable()
?check_sentiment.ai
# Test run
init_sentiment.ai()
# Package names
packages <- c("rtweet", "tidytext", "tidyverse", "wordcloud2", "textdata", "sentiment.ai", "SentimentAnalysis", "sentimentr", "lubridate", "sentiment.ai", "SentimentAnalysis", 'here')
# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
install.packages(packages[!installed_packages])
}
# Load packages
invisible(lapply(packages, library, character.only = TRUE))
# Test run
init_sentiment.ai()
# Package names
packages <- c("rtweet", "tidytext", "tidyverse", "wordcloud2", "textdata", "sentiment.ai", "SentimentAnalysis", "sentimentr", "lubridate", "sentiment.ai", "SentimentAnalysis", 'here')
# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
install.packages(packages[!installed_packages])
}
# Load packages
invisible(lapply(packages, library, character.only = TRUE))
# Test run
init_sentiment.ai()
sentiment_score(c("This installation process is too complicated!",
"Only if it works in the end.",
"But does it?",
"It does work!"))
?sentiment.ai::install_sentiment.ai
# Package names
packages <- c("rtweet", "tidytext", "tidyverse", "wordcloud2", "textdata", "sentiment.ai", "SentimentAnalysis", "sentimentr", "lubridate", "sentiment.ai", "SentimentAnalysis", 'here')
# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
install.packages(packages[!installed_packages])
}
# Load packages
invisible(lapply(packages, library, character.only = TRUE))
knitr::include_graphics("miniconda.JPG")
# You need to run it only once.
install_sentiment.ai(envname = "r-sentiment-ai",
method = "conda",
python_version = "3.8.10")
install.packages('NHSRtheme')
