---
title: "Sentiment Analysis"
author: "Bonwoo Koo and Subhro Guhathakurta"
date: '2022-11-8'
output:
  rmdformats::downcute:
    downcute_theme: "chaos"
---

<style type="text/css">
  body{
  font-family: Arial;
  }
</style>


```{r load-packages, include=FALSE}
# Package names
packages <- c("rtweet", "tidytext", "tidyverse", "wordcloud2", "textdata", "sentiment.ai", "SentimentAnalysis", "sentimentr", "lubridate", "sentiment.ai", "SentimentAnalysis", 'here')

# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
install.packages(packages[!installed_packages])
}

# Load packages
invisible(lapply(packages, library, character.only = TRUE))
```

**DISCLAIMER**: Due to the rapid production of tweets, and that they are uncensored, I can’t be sure that you may not see some images that are not suited for work / school. You may see some that are controversial as well. This is part of the urban analytics field. That said, I hope no one gets offended or upset by anything we may encounter. 

# Section 0. Get your API credential

If you don't have credentials for Twitter API, go to [this webpage](https://bonwookoo.github.io/UrbanAnalytics2022/Lab/module_4/getting_key.html) to find instructions on how to get one for yourself. 

Note that there are multiple *tiers* in Twitter API - Essential Access, Elevated Access, and Academic Research Access. Each level has their own caps in terms of the maximum number of Apps per Project, Tweet consumption per month, and others (see [this page](https://developer.twitter.com/en/docs/projects/overview) for more details). 

Twitter API provides a very well-organized document that's great for understanding the structure of the API. There are Apps and Projects in Twitter API that help you organize your work. Each Project can contain a single App if you have Essential access, and up to three Apps if you have Elevated or greater access. We will be using **Elevated Access** that allows up to 3 Apps within a Project and Tweet consumption cap of 2 million Tweets per month.



# Section 1. Setup for Sentiment Analysis

Sentiment analysis refers to the use of natural language processing and/or other related techniques to quantify affective states often from text data ([source](https://en.wikipedia.org/wiki/Sentiment_analysis)). Like we've experienced for computer vision, recent developments introduced some nicely packaged models that we can easily use out of the box. This document will introduce two different packages for sentiment analysis in R. First is **[SentimentAnalysis package](https://cran.r-project.org/web/packages/SentimentAnalysis/vignettes/SentimentAnalysis.html)**, which uses dictionary-based approach. On the benefits of dictionary-based approach, their vignette states,

>"On the one hand, machine learning approaches are preferred when one strives for high prediction performance. However, machine learning usually works as a black-box, thereby making interpretations diffucult. On the other hand, dictionary-based approaches generate lists of positive and negative words. The respective occurrences of these words are then combined into a single sentiment score. Therefore, the underlying decisions become traceable and researchers can understand the factors that result in a specific sentiment."

The Second package is **[sentiment.ai](https://benwiseman.github.io/sentiment.ai/).** This package is based on deep learning architecture and "... is relatively simple and out performs the current best offerings on CRAN and even Microsoft’s Azure Cognitive Services" according to the developers. 

## Installation
Unlike other packages we've used so far, this sentiment.ai package is not easy to install (they use the word 'notorious' when they describe installation process).

1. Go to https://docs.conda.io/en/latest/miniconda.html and download Miniconda3 Windows 64-bit installer. Install Miniconda by keep clicking 'Next' and 'Install.'

2. If your RStudio is currently open, close it and open it again.
3. Load the package using `library(sentiment.ai)`.
4. Run the following code. It will install a lot of stuff and will restart R session at the end. Next time you open RStudio, you don't need to run this code again.

```{r, eval=FALSE}
# You need to run it only once.
install_sentiment.ai(envname = "r-sentiment-ai",
                     method = "conda",
                     python_version = "3.8.10")
```

5. After R session is restarted, run the following code:

```{r}
# Sam's solution
init_sentiment.ai(envname = "r-sentiment-ai", method="conda")

check_sentiment.ai()
```

If you are asked if you wanted to install Miniconda, hit y. This Miniconda is different from the one you've already installed because this one is for the use within R. This function may print some error messages, but that's fine as long as the final message says NULL. 

6. Run the following code for testing purpose.

```{r}
sentiment_score(c("This installation process is too complicated!", 
                  "Only if it works in the end.", 
                  "But does it?", 
                  "It does work!"))
```

**If you can see associated sentiment scores for each sentence, the installation is successful.**

## Comparing sentiment analysis results from the two packages
Using some sample texts, let's compare the two packages. This example is borrowed from [sentiment.ai](https://benwiseman.github.io/sentiment.ai/).

**<font color=pink> Remember that next time you close and open RStudio, you don't need to use install_sentiment.ai() and check_sentiment.ai() function. You can just do library(sentiment.ai) and init_sentiment.ai() to get ready to do sentiment analysis using sentiment.ai package.</font>**


```{r}
# Assuming you've freshly opened RStudio..
library(sentiment.ai)

# Example texts
text <- c(
    "What a great car. It stopped working after a week.",
    "Steve Irwin working to save endangered species",
    "Bob Ross teaching people how to paint",
    "I saw Adolf Hitler on my vacation in Argentina...",
    "the resturant served human flesh",
    "the resturant is my favorite!",
    "the resturant is my favourite!",
    "this restront is my FAVRIT innit!",
    "the resturant was my absolute favorite until they gave me food poisoning",
    "This fantastic app freezes all the time!",
    "I learned so much on my trip to Hiroshima museum last year!",
    "What happened to the people of Hiroshima in 1945",
    "I had a blast on my trip to Nagasaki",
    "The blast in Nagasaki",
    "I love watching scary horror movies",
    "This package offers so much more nuance to sentiment analysis!",
     "you remind me of the babe. What babe? The babe with the power! What power? The power of voodoo. Who do? You do. Do what? Remind me of the babe!"
)

# sentiment.ai
sentiment.ai.score <- sentiment_score(text)

# Sentiment Analysis
sentimentAnalysis.score <- SentimentAnalysis::analyzeSentiment(text)$SentimentQDAP

example <- data.frame(target = text, 
                      sentiment.ai = sentiment.ai.score,
                      sentimentAnalysis = sentimentAnalysis.score)

rownames(example) <- NULL

example %>% 
  kableExtra::kable()
```


# Section 2. Sentiment analysis on Tweets

Now that we have a powerful tool in our hands, let's apply it to Tweets!

```{r, include=FALSE}
# whatever name you assigned to your created app
appname <- "UrbanAnalytics_tutorial"

# create token named "twitter_token"
# the keys used should be replaced by your own keys obtained by creating the app  

twitter_token <- create_token(
 app = appname,
  consumer_key = Sys.getenv("twitter_key"), 
  consumer_secret = Sys.getenv("twitter_key_secret"),
  access_token = Sys.getenv("twitter_access_token"),
  access_secret = Sys.getenv("twitter_access_token_secret"))
```


## Getting Tweets from user timelines
To acquire enough number of Tweets for class exercise, we will collect Tweets from the timeline of some famous figures.

**This section is heavily borrowed from [Median](https://medium.com/the-artificial-impostor/analyzing-tweets-with-r-92ff2ef990c6)**
```{r}
# Get time lines
obama <- rtweet::get_timeline("BarackObama", n = 3200)
biden <- rtweet::get_timeline("JoeBiden", n=3200)

# Add screen nam
obama <- bind_cols(obama, 
                   users_data(obama) %>% select(screen_name, location))

biden <- bind_cols(biden, 
                   users_data(biden) %>% select(screen_name, location))

# Row-bind the two
tweets <- bind_rows(
  obama %>% select(text, screen_name, created_at, retweet_count, favorite_count),
  biden %>% select(text, screen_name, created_at, retweet_count, favorite_count)
  )
```

```{r}
# Regex that matches URL-type string
replace_reg <- "http[s]?://[A-Za-z\\d/\\.]+|&amp;|&lt;|&gt;"

# Tidy the string
tidy_tweets_words <- tweets %>% 
  # Drop retweets
  filter(!str_detect(text, "^RT")) %>%
  # Drop URLs
  mutate(text = str_replace_all(text, replace_reg, ""),
         text = gsub("@", "", text),
         text = gsub("\n\n", "", text)) %>%
  # Add id column
  mutate(id = row_number())

tidy_tweets_words
```

## Applying Sentiment Analysis and visualize the results
```{r, message=FALSE, warning=FALSE}
tidy_tweets_words <- tidy_tweets_words %>% 
  mutate(sentiment_ai = sentiment_score(text),
         sentimentAnaly = SentimentAnalysis::analyzeSentiment(text)$SentimentQDAP)

tidy_tweets_words %>% 
  mutate(ym = format(created_at, "%Y-%m")) %>% 
  group_by(screen_name, ym) %>% 
  summarise(sentiment = mean(sentiment_ai),
            retweet_count = log(mean(retweet_count))) %>% 
  mutate(ym = ym(ym)) %>% 
  ggplot(data = .) +
  geom_line(mapping = aes(x = ym, y = sentiment, color = retweet_count), lwd = 1) +
  facet_wrap(~screen_name) +
  scale_color_gradient(low="red", high="green") +
  labs(x = "Time Line", 
      y = "Sentiment Score \n",
      title = "Sentiment Score of Tweets from US presidents",
      subtitle = "Sentiment Score: -1 (negative) ~ +1 (positive)",
      color = "Retweet Count (logged)")
```




## Try with your own search key words 
 
One example you can try is the names of different neighborhoods in Atlanta. How can you make sure that the neighborhood names you search are not from other cities?

Of course, feel free to pick whatever Tweets you want to test out.



























