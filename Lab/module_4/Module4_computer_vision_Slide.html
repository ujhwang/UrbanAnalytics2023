<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Urban Images and Computer Vision</title>
    <meta charset="utf-8" />
    <meta name="author" content="Originally written by Bon Woo Koo &amp; Subhro Guhathakurta; modified by Uijeong Hwang" />
    <script src="libs/header-attrs-2.25/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="assets/sydney-fonts.css" type="text/css" />
    <link rel="stylesheet" href="assets/sydney.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">

class: middle, inverse

# Urban Images and Computer Vision

.font100[
Subhro Guhathakurta &amp; Uijeong Hwang

10/19/2023
]





---
## Module 4 in a nutshell

1. Get Google API key.
2. Download street network data (OSM) and clean it.
3. Generate points along the edges. These will be where GSV images will be downloaded.
4. Calculate the heading of the cameras for each point. 
5. Create a function that takes a point as input and download GSV images.
6. Apply computer vision to the images.
7. Merge the results back to the points from Step 2.  
  
.small[
* Your Google API key should be ready by next Tuesday.
* We will cover Steps 2-5 next Tuesday and Steps 6-7 next Thursday.
* We will use Google Colab for the computer vision part (Steps 6-7).
]

---
## Google Colab(oratory)

* Google Colab is a cloud-based Jupyter notebook service hosted by Google.
* The free tier has 12 hour limit; after 12 hours of computation, your session will expire.

&lt;img src="img/colab_option.png" width="60%" /&gt;
  
---
class: inverse, middle, center

# Street View Images

---
## Why Street View Images

* Measuring built environment is important for numerous reasons - public health, public safety, environmental sustainability, economic vitality, tourism, etc.
* Built environment literature commonly differentiate between the urban form and streetscape.
  * ***Urban form***: macroscale-built environment which characterizes street connectivity, density, and diversity of land use.
  * ***Streetscape***: pertains to physical layout and design of the built environment, such as **sidewalk width, enclosure, tree canopy, landscaping, and street furniture**.

---
## Why Street View Images

* Researchers and practitioners had to conduct a field survey to collect information on streetscapes.
* Street view images can replace some parts of the field survey.

![](img/walking_audit.png)
.footnotesize[
(source: https://www.times-standard.com/2023/07/17/humboldt-county-cities-to-see-a-walk-audit/; https://www.clintonherald.com/news/local_news/groups-perform-walking-audit/article_29242512-f757-58b3-b1e8-7450509367c7.html)
]


---
## Street View Images API

* Google Street View
* Bing Maps Streetside View
* Mapillary: platform for sharing crowdsourced geotagged street view images; acquired by Meta in 2020.
&gt; Compare [Google](https://maps.app.goo.gl/Vc9kw9WNnWC6QywN9), [Bing](https://www.bing.com/maps?cp=33.776839%7E-84.389371&amp;lvl=15.4&amp;pi=6.8&amp;style=x&amp;mo=om.1&amp;dir=85.1), and [Mapillary](https://www.mapillary.com/app/?lat=33.776851232857&amp;lng=-84.389502582857&amp;z=17&amp;pKey=908091313101146&amp;focus=photo&amp;x=0.494875692639787&amp;y=0.6273840659246637&amp;zoom=0) street view images.

---
## Google Street View Images 

* Images taken at roughly 10 meter intervals from cameras that are (often but not always) mounted on car roof.
* 360-degree image in all directions.
* Have coverage both in US and internationally and can go back in time. 

&lt;img src="img/street_view_car.png" width="50%" /&gt;
  
.footnotesize[Source: Google]

---
## Google Street View Images

* Around 2010, planning studies started using Google Street View (GSV) images to audit street environments.
* In early studies, human auditors were looking at GSV and did manual audits.
* Recent studies are increasingly using computer vision instead of manual audits.

---
## Google Street View Images

* Web version of GSV is free but **.red[their API is NOT FREE!]** (7.00 USD per 1000 images)
* You get $200 credit every month, so you can get about 28,000 street view images per month.
* Maximum Queries per Minute (QPM): 30,000.
* Do not distribute images.
* You should **.red[NEVER EXPOSE]** your API key. You can get charged for a lot of money.

---

.pull-left[
.center[
**GSV from web**
]
![web](img/gsv_web.JPG)
]

.pull-right[
.center[
**GSV from API**
]
![api](img/gsv_api.jfif)
]

---
## Example Request

.center[
https://maps.googleapis.com/maps/api/streetview?.red[size=600x300].blue[&amp;location=46.414382,10.013988]&lt;br&gt;.orange[&amp;heading=151.78].pink[&amp;pitch=-0.76].green[&amp;key=YOUR_API_KEY]
]

* **Size**: Capped at 640x 640 pixels.
* **Location**: latitude and longitude.
* **Heading**: Heading of the camera &lt;br&gt;.small[.gray[(0=North, 90=East, 180=South, 270=West, 360=North)]]
* **Pitch** (default 0): Specified up or down angle of the camera.
* **fov**: (default 90): determines the field of view of the image.
* **key**: Your API key.

---
class: inverse, middle, center

# Computer Vision

---
## Computer vision
* Computer vision is the field of AI (particularly, deep learning) that enables computers to interpret and understand visual information.
* Deep learning is part of a broader family of AI methods based on **artificial neural networks**.
* Example architecture: Convolutional Neural Network (CNN)
![](img/cnn.jpg)
  
.footnotesize[
(source: https://medium.com/@eric.perbos/fast-ai-deep-learning-for-coders-part-1-2017-3db56c1a4cf3)
]

---
## Computer vision
* Deep learning algorithms are stacked in a hierarchy of increasing complexity and abstraction
  
![](img/stacked_complexity.png)

.footnotesize[
(source: https://medium.com/analytics-vidhya/convolutional-neural-network-an-informal-intro-part-1-db9fca86a750)
]

---
## Classification
* Image classification: [3D interactive visualization of CNN](https://adamharley.com/nn_vis/cnn/3d.html) (source: adamharley.com) 
![](img/digit_classification.png)

---
## Segmentation
* Segmentation models detect 'Things' and 'Stuff' from an image.
* Things: countable objects such as person, bike, and car.
* Stuff: uncountable region of identical texture, such as sky and road.

&lt;img src="img/stuff_things.png" width="70%" /&gt;
.footnotesize[
(source: https://viso.ai/deep-learning/image-segmentation-using-deep-learning/)
]

---
## Segmentation
* Semantic Segmentation: Classifies each pixel of an image into a class.
* Instance Segmentation: Detects objects and distinguishes instances.
* Panoptic Segmentation: Combines the two methods above.

&lt;img src="img/segmentation_types.png" width="73%" /&gt;
.footnotesize[
(source: https://arxiv.org/pdf/2006.12567.pdf)
]


---
class: inverse, middle, center

# Levaraging Street View Images and Computer Vision in Urban Studies


---
## Case 1: Street view images to aerial image


* Aerial images are often unsuitable for examining road infrastructure.

&lt;img src="img/aerial_issue.png" width="60%" /&gt;

---
## Case 1: Street view images to aerial image

* "If I have street view images from four directions and transform somehow, I may be able to recreate aerial image?"


&lt;img src="img/four_street_view_images.png" width="60%" /&gt;


---
### Inverse perspective transformation

![](img/inverse_perspective.jpg)

---
### Comparison between aerial image and recreated aerial image

![](img/aerial_street_view.png)

---
### Examples of recreated aerial image

&lt;img src="img/example_1.png" width="100%" /&gt;

---
### Examples of recreated aerial image

&lt;img src="img/example_2.png" width="100%" /&gt;

---
### Examples of recreated aerial image

&lt;img src="img/example_3.png" width="100%" /&gt;

---
## Case 2: Streetscape and servicescape
.small[
* Research question: **"Can walkable streetscapes make local businesses more attractive?"**
* Method: Customer satisfaction (from Yelp review rating) ~ streetscape elements (from semantic &amp; instance segmentation models)
* Findings: Greenness, building-to-street ratio, and sidewalk buffer have a positive impact on customer satisfaction of nearby restaurants.
]

&lt;img src="img/streetscape-servicescape.gif" width="80%" /&gt;

---
## Case 3: Perception of streetscape and bike lanes

* Research question: **“Do bike lanes in low-income neighborhoods—which are often perceived as less safe and unappealing—yield the same results as those in safer, more affluent neighborhoods?”**

* In other words, **"Does the impact of bike lanes on encouraging biking differ by the perception of streetscapes?"**

&lt;img src="img/good_bad_streetscape.png" width="100%" /&gt;

---
### Operational approach

1. **Train** a Deep Learning model that predicts a “perception” (value) from a given “streetscape” (image).

2. **Infer** perception scores of street images for an entire city using the trained model.

3. **Model** the associations between perception of streetscape, bike lanes, and biking behaviors.

---
### Training data: Place Pulse 2.0
* Online crowdsourced dataset of perceptual attributes – **safe**, lively, beautiful, wealthy, depressing, and boring – of street view images collected by researchers at the MIT Media Lab.

![](img/place_pulse.png)

---
### Training: transfer learning
* Transfer learning leverages the knowledge of a pre-trained model, instead of training from scratch

![](img/transfer_learning_1.png)

---
### Training: transfer learning
* Transfer learning leverages the knowledge of a pre-trained model, instead of training from scratch

![](img/transfer_learning_2.png)

---
### Training result
&lt;img src="img/training_result.png" width="80%" /&gt;
  
---
### Inference data: Mapillary
* There are 7.4 million Mapillary street view image in Berlin, Germany.
* I sampled 380,000 images and applied the trained model.

![](img/mapillary_berlin.png)

---
### Inference result

![](img/visual_safety_score.png)

---
### Inference result

![](img/visual_safety_score_map.png)

---
## Google API key

* Follow the instruction [here](https://raw.githubusercontent.com/ujhwang/UrbanAnalytics2023/main/Lab/module_4/how_to_get_your_key.pptx) to get your Google API key.
* Once you complete getting the key, I highly recommend setting up a budget alert (Billing --&gt; Budgets &amp; alerts --&gt; create budget).
* Add your Google API key to the system environment variable.
  - You can follow the same steps we used for the Census API and Yelp API keys.
  - If you are using Docker, you will need to create a new container.

---

## Try it

This URL (with your key added) will give you an image at Tech Square.


https://maps.googleapis.com/maps/api/streetview?size=640x640&amp;location=33.7768249,-84.388767&amp;heading=224.96&amp;&lt;br&gt;fov=90&amp;pitch=0&amp;key=YOUR_API_KEY


* Try different heading, fov, and pitch.
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "4:3"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
